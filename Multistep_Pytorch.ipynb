{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Processing and Feature Extraction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data and get rid of duplicate data\n",
    "data_df = pd.read_csv('data.csv')\n",
    "data_df = data_df.drop_duplicates(['date', 'temperature', 'venue', 'precipitation'])\n",
    "\n",
    "# Fill NaN values with -1\n",
    "data_df = data_df.fillna(-1)\n",
    "\n",
    "# Convert date column to datetime type and sort dataframe by date\n",
    "data_df['date'] = pd.to_datetime(data_df['date'])\n",
    "data_df.sort_values(by=['date'], inplace=True, ascending=True)\n",
    "\n",
    "# Narrow date range\n",
    "year1_df = data_df.loc[(data_df['date'] >= '2017-10-16') & (data_df['date'] <= '2018-01-31')].copy()\n",
    "year2_df = data_df.loc[(data_df['date'] >= '2018-10-16') & (data_df['date'] <= '2019-01-31')].copy()\n",
    "\n",
    "# Group by venue for further processing\n",
    "year1_df = year1_df.groupby('venue')['temperature','precipitation'].agg(lambda x: list(x))\n",
    "year2_df = year2_df.groupby('venue')['temperature','precipitation'].agg(lambda x: list(x))\n",
    "\n",
    "# Drop American Airlines Center and Staples Center\n",
    "year1_df = year1_df.drop(['American Airlines Center','Staples Center']).reset_index()\n",
    "year2_df = year2_df.drop(['American Airlines Center','Staples Center']).reset_index()\n",
    "\n",
    "X = []\n",
    "test = []\n",
    "\n",
    "# Create training and validation data\n",
    "for item in year1_df['temperature'].values:\n",
    "    X.append(item[-20:])\n",
    "\n",
    "for item in year2_df['temperature'].values:\n",
    "    test.append(item[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Build model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sequence, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(1, 101)\n",
    "        self.lstm2 = nn.LSTMCell(101, 101)\n",
    "        self.linear = nn.Linear(101, 1)\n",
    "\n",
    "    def forward(self, input, future = 0):\n",
    "        outputs = []\n",
    "        h_t = torch.zeros(input.size(0), 101, dtype=torch.double)\n",
    "        c_t = torch.zeros(input.size(0), 101, dtype=torch.double)\n",
    "        h_t2 = torch.zeros(input.size(0), 101, dtype=torch.double)\n",
    "        c_t2 = torch.zeros(input.size(0), 101, dtype=torch.double)\n",
    "\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        for i in range(future):# if we should predict the future\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  0\n",
      "loss: 2533.0790213149407\n",
      "loss: 2533.046361255846\n",
      "loss: 2395.1085218570292\n",
      "loss: 2391.139873129242\n",
      "loss: 2387.1656203407465\n",
      "loss: 2383.1841237936565\n",
      "loss: 2379.1941048162917\n",
      "loss: 2375.194486294863\n",
      "loss: 2371.184340238463\n",
      "loss: 2367.162871836824\n",
      "loss: 2363.1294125176764\n",
      "loss: 2359.083412234066\n",
      "loss: 2355.0244284401574\n",
      "loss: 2350.9521119136757\n",
      "loss: 2346.866190386461\n",
      "loss: 2342.7664510229283\n",
      "loss: 2338.6527226349513\n",
      "loss: 2334.524858330661\n",
      "loss: 2330.382719124196\n",
      "loss: 2326.2261588987826\n",
      "test loss: 2252.4574126165853\n",
      "STEP:  1\n",
      "loss: 2322.055011020794\n",
      "loss: 2317.869076855476\n",
      "loss: 2313.6681164499105\n",
      "loss: 2309.4518417454706\n",
      "loss: 2305.2199128824814\n",
      "loss: 2300.971938485939\n",
      "loss: 2296.7074812848014\n",
      "loss: 2292.426071009995\n",
      "loss: 2288.127227182289\n",
      "loss: 2283.8104949943854\n",
      "loss: 2279.4754977059747\n",
      "loss: 2275.122008255272\n",
      "loss: 2270.7500402978026\n",
      "loss: 2266.359953581357\n",
      "loss: 2261.9525597622974\n",
      "loss: 2257.529203286102\n",
      "loss: 2253.091781796707\n",
      "loss: 2248.6426696738336\n",
      "loss: 2244.184525828939\n",
      "loss: 2239.720004908707\n",
      "test loss: 2163.7180286158723\n",
      "STEP:  2\n",
      "loss: 2235.2514358118497\n",
      "loss: 2230.780555763618\n",
      "loss: 2226.3083713598876\n",
      "loss: 2221.835166939932\n",
      "loss: 2217.3606270402256\n",
      "loss: 2212.884012748972\n",
      "loss: 2208.404336875338\n",
      "loss: 2203.9205053404767\n",
      "loss: 2199.4314149221987\n",
      "loss: 2194.936011788553\n",
      "loss: 2190.4333208353255\n",
      "loss: 2185.9224559511163\n",
      "loss: 2181.402619163778\n",
      "loss: 2176.8730940973965\n",
      "loss: 2172.333237093333\n",
      "loss: 2167.782467892816\n",
      "loss: 2163.2202608524713\n",
      "loss: 2158.646137117046\n",
      "loss: 2154.059657871402\n",
      "loss: 2149.460418640451\n",
      "test loss: 2071.3203895043225\n",
      "STEP:  3\n",
      "loss: 2144.8480445368114\n",
      "loss: 2140.2221863338345\n",
      "loss: 2135.582517242426\n",
      "loss: 2130.9287302821476\n",
      "loss: 2126.2605361526053\n",
      "loss: 2121.5776615273194\n",
      "loss: 2116.8798477070336\n",
      "loss: 2112.1668495824697\n",
      "loss: 2107.438434867357\n",
      "loss: 2102.6943835717057\n",
      "loss: 2097.934487692144\n",
      "loss: 2093.1585511018284\n",
      "loss: 2088.3663896260337\n",
      "loss: 2083.55783129187\n",
      "loss: 2078.7327167410876\n",
      "loss: 2073.89089979409\n",
      "loss: 2069.032248150439\n",
      "loss: 2064.156644206895\n",
      "loss: 2059.263985967932\n",
      "loss: 2054.3541880161724\n",
      "test loss: 1973.8157558121547\n",
      "STEP:  4\n",
      "loss: 2049.4271825014985\n",
      "loss: 2044.4829200982572\n",
      "loss: 2039.5213708709748\n",
      "loss: 2034.5425249810453\n",
      "loss: 2029.5463931617924\n",
      "loss: 2024.533006887886\n",
      "loss: 2019.5024181693132\n",
      "loss: 2014.4546989105515\n",
      "loss: 2009.3899397929647\n",
      "loss: 2004.3082486625976\n",
      "loss: 1999.2097484347955\n",
      "loss: 1994.0945745596407\n",
      "loss: 1988.9628721246947\n",
      "loss: 1983.8147927003436\n",
      "loss: 1978.6504910550732\n",
      "loss: 1973.4701218799912\n",
      "loss: 1968.2738366624844\n",
      "loss: 1963.0617808379154\n",
      "loss: 1957.834091326908\n",
      "loss: 1952.5908945369413\n",
      "test loss: 1869.4970329162113\n",
      "STEP:  5\n",
      "loss: 1947.3323048740046\n",
      "loss: 1942.0584237766752\n",
      "loss: 1936.7693392543845\n",
      "loss: 1931.4651258867225\n",
      "loss: 1926.1458452222773\n",
      "loss: 1920.8115465050548\n",
      "loss: 1915.4622676526162\n",
      "loss: 1910.098036412608\n",
      "loss: 1904.7188716311762\n",
      "loss: 1899.324784576927\n",
      "loss: 1893.9157802759769\n",
      "loss: 1888.491858826144\n",
      "loss: 1883.0530166707122\n",
      "loss: 1877.5992478237922\n",
      "loss: 1872.1305450498667\n",
      "loss: 1866.646901009531\n",
      "loss: 1861.1483093916063\n",
      "loss: 1855.6347660590252\n",
      "loss: 1850.106270241914\n",
      "loss: 1844.562825816248\n",
      "test loss: 1758.7329705075033\n",
      "STEP:  6\n",
      "loss: 1839.0044427101543\n",
      "loss: 1833.4311384819216\n",
      "loss: 1827.8429401134786\n",
      "loss: 1822.2398860594562\n",
      "loss: 1816.6220285839836\n",
      "loss: 1810.98943640306\n",
      "loss: 1805.3421976284294\n",
      "loss: 1799.6804229772977\n",
      "loss: 1794.0042491699235\n",
      "loss: 1788.3138423838518\n",
      "loss: 1782.609401570953\n",
      "loss: 1776.8911613766365\n",
      "loss: 1771.1593943372768\n",
      "loss: 1765.4144119856928\n",
      "loss: 1759.6565644808666\n",
      "loss: 1753.8862384148865\n",
      "loss: 1748.1038525519323\n",
      "loss: 1742.3098514261578\n",
      "loss: 1736.5046969588793\n",
      "loss: 1730.6888585214049\n",
      "test loss: 1641.9624642464073\n",
      "STEP:  7\n",
      "loss: 1724.8628021233094\n",
      "loss: 1719.0269795915665\n",
      "loss: 1713.1818186743603\n",
      "loss: 1707.3277149276541\n",
      "loss: 1701.4650260284932\n",
      "loss: 1695.594068847662\n",
      "loss: 1689.7151192704805\n",
      "loss: 1683.82841444607\n",
      "loss: 1677.9341569259275\n",
      "loss: 1672.032520046585\n",
      "loss: 1666.1236539143626\n",
      "loss: 1660.2076914367308\n",
      "loss: 1654.2847539785926\n",
      "loss: 1648.3549563692443\n",
      "loss: 1642.4184111207965\n",
      "loss: 1636.4752318271671\n",
      "loss: 1630.5255357892363\n",
      "loss: 1624.5694459585673\n",
      "loss: 1618.6070923144116\n",
      "loss: 1612.638612793706\n",
      "test loss: 1520.9629572788685\n",
      "STEP:  8\n",
      "loss: 1606.664153887415\n",
      "loss: 1600.6838710039106\n",
      "loss: 1594.6979286848175\n",
      "loss: 1588.7065007432739\n",
      "loss: 1582.7097703797317\n",
      "loss: 1576.7079303174705\n",
      "loss: 1570.7011829883156\n",
      "loss: 1564.6897407889555\n",
      "loss: 1558.6738264192015\n",
      "loss: 1552.6536733051296\n",
      "loss: 1546.6295261022453\n",
      "loss: 1540.6016412660065\n",
      "loss: 1534.5702876696043\n",
      "loss: 1528.5357472414753\n",
      "loss: 1522.4983155880932\n",
      "loss: 1516.458302561427\n",
      "loss: 1510.4160327256836\n",
      "loss: 1504.37184567496\n",
      "loss: 1498.326096153345\n",
      "loss: 1492.2791539318323\n",
      "test loss: 1397.6102560726292\n",
      "STEP:  9\n",
      "loss: 1486.2314034030587\n",
      "loss: 1480.1832428652824\n",
      "loss: 1474.1350834808097\n",
      "loss: 2301.7314628864174\n",
      "loss: 2254.8542923024843\n",
      "loss: 2195.008523494429\n",
      "loss: 1517.7942759375114\n",
      "loss: 1489.6971477127888\n",
      "loss: 1456.437532234478\n",
      "loss: 1122.7735977125028\n",
      "loss: 1050.6015597146122\n",
      "loss: 1028.8311563832858\n",
      "loss: 1001.1555046544647\n",
      "loss: 941.6615614469852\n",
      "loss: 864.4100031479398\n",
      "loss: 766.6547090573654\n",
      "loss: 762.366580764986\n",
      "loss: 755.5658901382191\n",
      "loss: 745.369219119479\n",
      "loss: 729.7757530425067\n",
      "test loss: 545.2826561177963\n",
      "STEP:  10\n",
      "loss: 705.3460178916474\n",
      "loss: 675.1459930627715\n",
      "loss: 655.1190297110934\n",
      "loss: 640.9462225305318\n",
      "loss: 628.856355049813\n",
      "loss: 617.5374423817755\n",
      "loss: 606.6763512285531\n",
      "loss: 596.2917671619253\n",
      "loss: 586.4376173187482\n",
      "loss: 577.080874114798\n",
      "loss: 568.1057863259576\n",
      "loss: 559.3754242802767\n",
      "loss: 550.7833604390621\n",
      "loss: 542.256410690596\n",
      "loss: 533.663786234766\n",
      "loss: 524.5784044872262\n",
      "loss: 513.1249574905769\n",
      "loss: 451.31019832720943\n",
      "loss: 448.5761176567943\n",
      "loss: 446.31613905216284\n",
      "test loss: 299.38060360701354\n",
      "STEP:  11\n",
      "loss: 443.81838636796266\n",
      "loss: 441.0820865668576\n",
      "loss: 438.09819866182795\n",
      "loss: 434.80419714768686\n",
      "loss: 431.16063047812656\n",
      "loss: 426.978150701132\n",
      "loss: 421.85475074918105\n",
      "loss: 413.3935007761898\n",
      "loss: 379.61791407705107\n",
      "loss: 378.4755615201428\n",
      "loss: 376.8173786035102\n",
      "loss: 375.7349636700547\n",
      "loss: 374.8358960327525\n",
      "loss: 373.7858626740745\n",
      "loss: 372.5453449500827\n",
      "loss: 371.12949090673646\n",
      "loss: 369.34615866905597\n",
      "loss: 366.80130291675243\n",
      "loss: 357.1660798432769\n",
      "loss: 354.64756133709915\n",
      "test loss: 223.95756029554232\n",
      "STEP:  12\n",
      "loss: 354.25490164850464\n",
      "loss: 348.334792885864\n",
      "loss: 347.44149978344586\n",
      "loss: 347.2585361789982\n",
      "loss: 346.8111878460171\n",
      "loss: 346.2186013571169\n",
      "loss: 345.53538640449887\n",
      "loss: 344.78510722403684\n",
      "loss: 343.9524345364105\n",
      "loss: 342.96030907966997\n",
      "loss: 341.4535124937066\n",
      "loss: 328.23764068457507\n",
      "loss: 327.9996170040228\n",
      "loss: 327.75373229347605\n",
      "loss: 327.5006231745917\n",
      "loss: 327.24096416847146\n",
      "loss: 326.9754301327276\n",
      "loss: 326.7046650696861\n",
      "loss: 326.4292584422844\n",
      "loss: 326.14972893668624\n",
      "test loss: 204.17760363318584\n",
      "STEP:  13\n",
      "loss: 325.86651482441135\n",
      "loss: 325.57996969346823\n",
      "loss: 325.2903622545471\n",
      "loss: 324.99787908277267\n",
      "loss: 324.70262944120043\n",
      "loss: 324.40465169193544\n",
      "loss: 324.1039212077819\n",
      "loss: 323.80036015063433\n",
      "loss: 323.4938500018396\n",
      "loss: 323.1842483488109\n",
      "loss: 322.87141219379134\n",
      "loss: 322.5552309890981\n",
      "loss: 322.2356737038917\n",
      "loss: 321.91285534078287\n",
      "loss: 321.5871290065446\n",
      "loss: 321.2592089473843\n",
      "loss: 320.9303262061853\n",
      "loss: 317.2645405478929\n",
      "loss: 317.22086504019404\n",
      "loss: 317.19347483670737\n",
      "test loss: 206.4942535090949\n",
      "STEP:  14\n",
      "loss: 317.1162594830704\n",
      "loss: 316.9801335338647\n",
      "loss: 316.7795662805706\n",
      "loss: 316.50534702084497\n",
      "loss: 316.13640683773\n",
      "loss: 315.6231575028346\n",
      "loss: 314.82928959965136\n",
      "loss: 313.17088169863354\n",
      "loss: 303.290605478896\n",
      "loss: 303.2781405865056\n",
      "loss: 302.9465994110596\n",
      "loss: 302.0085278530523\n",
      "loss: 300.695828388483\n",
      "loss: 299.07566616148563\n",
      "loss: 297.07296639375585\n",
      "loss: 294.8784322814881\n",
      "loss: 292.6545219906655\n",
      "loss: 290.0492247748022\n",
      "loss: 285.93340906465187\n",
      "loss: 276.709260299177\n",
      "test loss: 168.41084252069354\n",
      "STEP:  15\n",
      "loss: 275.534323763519\n",
      "loss: 274.96983512864983\n",
      "loss: 274.22389989257647\n",
      "loss: 273.36210806392864\n",
      "loss: 272.45323085640246\n",
      "loss: 271.5134983590933\n",
      "loss: 270.52869288214225\n",
      "loss: 269.51272241047684\n",
      "loss: 268.4899739364383\n",
      "loss: 267.5190142383494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 266.64030850450314\n",
      "loss: 265.83986017698055\n",
      "loss: 265.0211660642584\n",
      "loss: 264.13643213485136\n",
      "loss: 263.1526555633389\n",
      "loss: 262.1873707026567\n",
      "loss: 261.2544398731877\n",
      "loss: 260.3334761138791\n",
      "loss: 259.4211197651094\n",
      "loss: 258.49540291015234\n",
      "test loss: 155.9599265745301\n",
      "STEP:  16\n",
      "loss: 257.57376949472564\n",
      "loss: 256.6337337238647\n",
      "loss: 255.68011339376713\n",
      "loss: 254.7061463795986\n",
      "loss: 253.7073496649465\n",
      "loss: 252.68691895055915\n",
      "loss: 251.63693021726775\n",
      "loss: 250.56636004120514\n",
      "loss: 249.46533707844983\n",
      "loss: 248.34906237806808\n",
      "loss: 247.2096408946129\n",
      "loss: 246.06772608435693\n",
      "loss: 244.9226680076319\n",
      "loss: 243.81386277723385\n",
      "loss: 242.7556450379654\n",
      "loss: 241.81276611474848\n",
      "loss: 240.9909994969991\n",
      "loss: 240.30353729399772\n",
      "loss: 239.70482331833506\n",
      "loss: 239.16385065104487\n",
      "test loss: 144.23515978746073\n",
      "STEP:  17\n",
      "loss: 238.62924499567688\n",
      "loss: 238.06620017929896\n",
      "loss: 237.3447388088472\n",
      "loss: 236.48938786760363\n",
      "loss: 235.71066093132103\n",
      "loss: 234.93536580248778\n",
      "loss: 234.1103396542221\n",
      "loss: 233.25901791818117\n",
      "loss: 232.39453485552522\n",
      "loss: 231.50348700109416\n",
      "loss: 230.60110627708082\n",
      "loss: 229.6674614533446\n",
      "loss: 228.73019322560683\n",
      "loss: 227.7618680485574\n",
      "loss: 226.78833646450818\n",
      "loss: 225.8018554816351\n",
      "loss: 224.78824964126406\n",
      "loss: 223.75852908892026\n",
      "loss: 222.7124585977992\n",
      "loss: 221.62845533063702\n",
      "test loss: 134.18340072314177\n",
      "STEP:  18\n",
      "loss: 220.51831814413154\n",
      "loss: 219.3259564043467\n",
      "loss: 218.02280188185821\n",
      "loss: 216.40657974799993\n",
      "loss: 213.68004988599515\n",
      "loss: 210.8603914068524\n",
      "loss: 207.58772366679858\n",
      "loss: 203.12868512736273\n",
      "loss: 198.60207397104372\n",
      "loss: 198.41163709537403\n",
      "loss: 198.08425408256292\n",
      "loss: 197.50964994712777\n",
      "loss: 197.1835164800545\n",
      "loss: 196.9475753611705\n",
      "loss: 196.70125674528987\n",
      "loss: 196.4336932926694\n",
      "loss: 196.1455775115498\n",
      "loss: 195.83842253993564\n",
      "loss: 195.5138625237591\n",
      "loss: 195.1734280930364\n",
      "test loss: 118.85857749071052\n",
      "STEP:  19\n",
      "loss: 194.8184476859335\n",
      "loss: 194.4499041656\n",
      "loss: 194.06847080986162\n",
      "loss: 193.6753802313978\n",
      "loss: 193.27205615072916\n",
      "loss: 192.8583443820299\n",
      "loss: 192.43516810088116\n",
      "loss: 192.00273661469507\n",
      "loss: 191.56161805174747\n",
      "loss: 191.1069914741316\n",
      "loss: 190.63368524628223\n",
      "loss: 190.06482653156021\n",
      "loss: 189.6309607675588\n",
      "loss: 189.20060765042453\n",
      "loss: 188.76428938634123\n",
      "loss: 188.33097477239377\n",
      "loss: 187.89956603754663\n",
      "loss: 187.47321330270424\n",
      "loss: 187.04706669530998\n",
      "loss: 186.61992213732736\n",
      "test loss: 117.15701728304701\n",
      "STEP:  20\n",
      "loss: 186.19188491221\n",
      "loss: 185.76477803985097\n",
      "loss: 185.32165226573042\n",
      "loss: 184.86583866982983\n",
      "loss: 184.31741365746325\n",
      "loss: 183.66527327768472\n",
      "loss: 182.60319377607416\n",
      "loss: 181.39357383202903\n",
      "loss: 180.92424319174467\n",
      "loss: 180.62594568173068\n",
      "loss: 180.32349443247392\n",
      "loss: 180.0290161429706\n",
      "loss: 179.69247843477936\n",
      "loss: 179.36958266952922\n",
      "loss: 179.03047745636616\n",
      "loss: 178.57769621162197\n",
      "loss: 178.23928707864283\n",
      "loss: 177.88265324053125\n",
      "loss: 177.50484308494183\n",
      "loss: 177.13161374479915\n",
      "test loss: 116.67308305183938\n",
      "STEP:  21\n",
      "loss: 176.75064680522104\n",
      "loss: 176.36941692920544\n",
      "loss: 175.98426624388924\n",
      "loss: 175.5918569634722\n",
      "loss: 175.1743979983152\n",
      "loss: 174.77752553949784\n",
      "loss: 174.2494147433315\n",
      "loss: 173.75698195536953\n",
      "loss: 172.90121827761877\n",
      "loss: 172.02995725020165\n",
      "loss: 171.0796494460666\n",
      "loss: 170.08876675838692\n",
      "loss: 170.03096829644227\n",
      "loss: 169.8006355129147\n",
      "loss: 169.51525429958124\n",
      "loss: 169.29275616034957\n",
      "loss: 169.06908892885917\n",
      "loss: 168.83357381062854\n",
      "loss: 168.58688766087232\n",
      "loss: 168.32532028063005\n",
      "test loss: 117.19415466228511\n",
      "STEP:  22\n",
      "loss: 168.05245764319443\n",
      "loss: 167.77125744547422\n",
      "loss: 167.48462765534913\n",
      "loss: 167.19718228742565\n",
      "loss: 166.90760671152682\n",
      "loss: 166.6149020895978\n",
      "loss: 166.3185687429027\n",
      "loss: 166.01768352451649\n",
      "loss: 165.71264501743792\n",
      "loss: 165.40373891833838\n",
      "loss: 165.09183040301605\n",
      "loss: 164.77769745190747\n",
      "loss: 164.4628193348242\n",
      "loss: 164.14842744927455\n",
      "loss: 163.83531364293546\n",
      "loss: 163.52409295692718\n",
      "loss: 163.21501582540324\n",
      "loss: 162.90891367559232\n",
      "loss: 162.60492722425235\n",
      "loss: 162.30361054961887\n",
      "test loss: 117.95004397090129\n",
      "STEP:  23\n",
      "loss: 162.00202830344546\n",
      "loss: 161.69770493515486\n",
      "loss: 161.37414111273804\n",
      "loss: 160.98544794124282\n",
      "loss: 160.29829934968708\n",
      "loss: 159.77012006794004\n",
      "loss: 159.51980929610235\n",
      "loss: 159.27384047491987\n",
      "loss: 159.0140241367318\n",
      "loss: 158.73276322921566\n",
      "loss: 158.47174292736094\n",
      "loss: 158.22380060463578\n",
      "loss: 157.98397423347066\n",
      "loss: 157.7505512881966\n",
      "loss: 157.52114126489792\n",
      "loss: 157.29429739711762\n",
      "loss: 157.07040224944765\n",
      "loss: 156.84828781148607\n",
      "loss: 156.6266202851576\n",
      "loss: 156.40395012873483\n",
      "test loss: 119.96123203045579\n",
      "STEP:  24\n",
      "loss: 156.18177364020892\n",
      "loss: 155.95465670856365\n",
      "loss: 155.7370840542839\n",
      "loss: 155.52129656649348\n",
      "loss: 155.30900742053493\n",
      "loss: 155.09667841914617\n",
      "loss: 154.88157905007623\n",
      "loss: 154.6673254286496\n",
      "loss: 154.4582610052004\n",
      "loss: 154.25460228855215\n",
      "loss: 154.05424200922624\n",
      "loss: 153.85479564317504\n",
      "loss: 153.6543668134311\n",
      "loss: 153.4517724255391\n",
      "loss: 153.24553648602105\n",
      "loss: 153.03948680646297\n",
      "loss: 152.82072939477231\n",
      "loss: 152.59110661990115\n",
      "loss: 152.36926823289298\n",
      "loss: 152.1477684515825\n",
      "test loss: 120.31525393724635\n",
      "STEP:  25\n",
      "loss: 151.9225374685046\n",
      "loss: 151.69494440531304\n",
      "loss: 151.46155710307076\n",
      "loss: 151.2249968066871\n",
      "loss: 150.98059983410207\n",
      "loss: 150.7321517672679\n",
      "loss: 150.4727972252424\n",
      "loss: 150.20705468371335\n",
      "loss: 149.9251925278719\n",
      "loss: 149.61009762832944\n",
      "loss: 149.27069268618467\n",
      "loss: 148.94618808043313\n",
      "loss: 148.6291350447269\n",
      "loss: 148.32909052862846\n",
      "loss: 148.05696451211145\n",
      "loss: 147.80661419737964\n",
      "loss: 147.57226237184815\n",
      "loss: 147.32707585775898\n",
      "loss: 147.11709899105514\n",
      "loss: 146.911245118234\n",
      "test loss: 120.19815660062135\n",
      "STEP:  26\n",
      "loss: 146.711203592072\n",
      "loss: 146.51441415009245\n",
      "loss: 146.33594937392172\n",
      "loss: 146.15500017186804\n",
      "loss: 145.9793662367448\n",
      "loss: 145.80020448350095\n",
      "loss: 145.6248646847144\n",
      "loss: 145.44978809148472\n",
      "loss: 145.28002412675707\n",
      "loss: 145.11129983350935\n",
      "loss: 144.9474449640086\n",
      "loss: 144.7857790964071\n",
      "loss: 144.62820948616107\n",
      "loss: 144.4729201285148\n",
      "loss: 144.32022977848817\n",
      "loss: 144.1698744720269\n",
      "loss: 144.0132605784907\n",
      "loss: 143.86263472539687\n",
      "loss: 143.71191860582917\n",
      "loss: 143.5587889229102\n",
      "test loss: 119.79936475300163\n",
      "STEP:  27\n",
      "loss: 143.42380301376934\n",
      "loss: 143.3011384144849\n",
      "loss: 143.1818363478165\n",
      "loss: 143.06344839486687\n",
      "loss: 142.94511320314382\n",
      "loss: 142.82427382471104\n",
      "loss: 142.69591014464186\n",
      "loss: 142.55205599071022\n",
      "loss: 142.3528451726062\n",
      "loss: 141.8700763029537\n",
      "loss: 141.36139846590024\n",
      "loss: 140.88824291891876\n",
      "loss: 140.84311268746043\n",
      "loss: 140.77906203376784\n",
      "loss: 140.70359337499542\n",
      "loss: 140.61792411912913\n",
      "loss: 140.51426360473027\n",
      "loss: 140.37192891625324\n",
      "loss: 140.2095989140245\n",
      "loss: 140.0182312627479\n",
      "test loss: 118.1439672893203\n",
      "STEP:  28\n",
      "loss: 139.76792716233632\n",
      "loss: 139.40341510209518\n",
      "loss: 138.97863657482878\n",
      "loss: 138.64351688113945\n",
      "loss: 138.4850503160763\n",
      "loss: 138.3238774908622\n",
      "loss: 138.03862868551178\n",
      "loss: 137.07027443204876\n",
      "loss: 136.77197285127875\n",
      "loss: 136.74386321082844\n",
      "loss: 136.7080468374908\n",
      "loss: 136.6586462400478\n",
      "loss: 136.60426763459213\n",
      "loss: 136.5377890668866\n",
      "loss: 136.43239717071592\n",
      "loss: 135.0066390848978\n",
      "loss: 134.99334443669733\n",
      "loss: 134.98001784411528\n",
      "loss: 134.96665198603856\n",
      "loss: 134.95323982945138\n",
      "test loss: 111.87395631319109\n",
      "STEP:  29\n",
      "loss: 134.9397747069363\n",
      "loss: 134.92625039701733\n",
      "loss: 134.91266120565913\n",
      "loss: 134.8990020470122\n",
      "loss: 134.8852685212806\n",
      "loss: 134.8714569874684\n",
      "loss: 134.85756462867138\n",
      "loss: 134.8435895076183\n",
      "loss: 134.82953061026217\n",
      "loss: 134.8153878754478\n",
      "loss: 134.80116220899473\n",
      "loss: 134.78685548096482\n",
      "loss: 134.77247050536704\n",
      "loss: 134.7580110021484\n",
      "loss: 134.7434815419122\n",
      "loss: 134.72888747443548\n",
      "loss: 134.71423484265762\n",
      "loss: 134.69953028434594\n",
      "loss: 134.68478092409595\n",
      "loss: 134.6699942586513\n",
      "test loss: 111.46909148756433\n",
      "STEP:  30\n",
      "loss: 134.65517803871725\n",
      "loss: 134.640340150486\n",
      "loss: 134.62548849997867\n",
      "loss: 134.6106309030719\n",
      "loss: 86731.68694519496\n",
      "loss: 84940.19472007595\n",
      "loss: 69305.0051942503\n",
      "loss: 68881.88205011383\n",
      "loss: 67207.84792235085\n",
      "loss: 65494.55094895187\n",
      "loss: 63722.06375616981\n",
      "loss: 61871.63833486405\n",
      "loss: 19200.43979893215\n",
      "loss: 18726.199895947582\n",
      "loss: 17906.505061038468\n",
      "loss: 17852.084235508115\n",
      "loss: 17690.125457594793\n",
      "loss: 17520.9816893488\n",
      "loss: 17340.984072251307\n",
      "loss: 17154.507449240882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 14576.753681434873\n",
      "STEP:  31\n",
      "loss: 16788.275893324037\n",
      "loss: 16468.299956142368\n",
      "loss: 16147.058617226108\n",
      "loss: 15824.132917158762\n",
      "loss: 15494.94073247012\n",
      "loss: 15147.075326403896\n",
      "loss: 14729.969416857895\n",
      "loss: 14255.01986921546\n",
      "loss: 14102.118443203051\n",
      "loss: 13984.083661493745\n",
      "loss: 38798.52619448645\n",
      "loss: 38256.43828706202\n",
      "loss: 37628.681655467604\n",
      "loss: 36281.461986484275\n",
      "loss: 33658.93219474876\n",
      "loss: 32245.680767200847\n",
      "loss: 8687.64279321028\n",
      "loss: 8560.07995440051\n",
      "loss: 8341.221517588772\n",
      "loss: 7955.052808927002\n",
      "test loss: 7628.226361511287\n",
      "STEP:  32\n",
      "loss: 7738.564463795189\n",
      "loss: 7399.064639879591\n",
      "loss: 6945.808944468646\n",
      "loss: 6692.07420755696\n",
      "loss: 6339.391965191997\n",
      "loss: 5879.067410736825\n",
      "loss: 5546.690911127905\n",
      "loss: 5265.065318052912\n",
      "loss: 4953.607438606138\n",
      "loss: 4668.805850275561\n",
      "loss: 4452.840567846323\n",
      "loss: 4252.137687816448\n",
      "loss: 3978.19976468705\n",
      "loss: 3852.1870211229434\n",
      "loss: 3788.3284756307003\n",
      "loss: 3682.8102702099613\n",
      "loss: 3499.080685958019\n",
      "loss: 3201.059133377419\n",
      "loss: 2903.16748258814\n",
      "loss: 2687.4073451240374\n",
      "test loss: 2325.2507991051575\n",
      "STEP:  33\n",
      "loss: 2516.683911659782\n",
      "loss: 2369.223217896169\n",
      "loss: 2222.4840560030902\n",
      "loss: 2063.487907611313\n",
      "loss: 1889.458109136967\n",
      "loss: 1690.0047910275453\n",
      "loss: 1495.8690980954364\n",
      "loss: 1443.0399561982892\n",
      "loss: 1412.2380885135283\n",
      "loss: 1377.0028300636168\n",
      "loss: 1335.3422339295305\n",
      "loss: 1290.026471182062\n",
      "loss: 1250.6567822864363\n",
      "loss: 1220.100876283547\n",
      "loss: 1194.2843549528263\n",
      "loss: 1170.4496616647384\n",
      "loss: 1148.1502149070288\n",
      "loss: 1128.0016894015332\n",
      "loss: 1110.7244302537206\n",
      "loss: 1096.4109213021645\n",
      "test loss: 897.4707065062436\n",
      "STEP:  34\n",
      "loss: 1084.5669012850942\n",
      "loss: 1074.546623214162\n",
      "loss: 1065.8325934996656\n",
      "loss: 1058.0619372069675\n",
      "loss: 1050.9859563609364\n",
      "loss: 1044.429418637928\n",
      "loss: 1038.2640229637811\n",
      "loss: 1032.392144896556\n",
      "loss: 1026.7365280252925\n",
      "loss: 1021.2336171787293\n",
      "loss: 1015.8289548886471\n",
      "loss: 1010.4738450312476\n",
      "loss: 1005.1228238876504\n",
      "loss: 999.7317494578541\n",
      "loss: 994.2565768051375\n",
      "loss: 988.6531976500689\n",
      "loss: 982.8790646153992\n",
      "loss: 976.8975735625427\n",
      "loss: 970.6849291371196\n",
      "loss: 964.2361608213273\n",
      "test loss: 781.6135821361232\n",
      "STEP:  35\n",
      "loss: 957.5642769556765\n",
      "loss: 950.6901038862525\n",
      "loss: 943.6294717590611\n",
      "loss: 936.3866125937044\n",
      "loss: 928.9545927072567\n",
      "loss: 921.3171828110645\n",
      "loss: 913.4477636482046\n",
      "loss: 905.3044378647743\n",
      "loss: 896.822883350671\n",
      "loss: 887.9088985455936\n",
      "loss: 878.4346503204745\n",
      "loss: 868.2520126171818\n",
      "loss: 857.2638299494596\n",
      "loss: 845.6283345608686\n",
      "loss: 834.0048383326894\n",
      "loss: 823.2107980943512\n",
      "loss: 813.4876022743208\n",
      "loss: 804.4573691366355\n",
      "loss: 795.65503831926\n",
      "loss: 786.8163630259882\n",
      "test loss: 628.0726827490204\n",
      "STEP:  36\n",
      "loss: 777.5586492044704\n",
      "loss: 767.1494532352988\n",
      "loss: 753.8625761099288\n",
      "loss: 736.1573236132855\n",
      "loss: 727.7911488000387\n",
      "loss: 720.9702138782881\n",
      "loss: 713.5367656376058\n",
      "loss: 705.9399304190237\n",
      "loss: 699.6271839642916\n",
      "loss: 693.9556316818723\n",
      "loss: 688.6526058266162\n",
      "loss: 683.8317290755396\n",
      "loss: 679.2957545256669\n",
      "loss: 674.3376178522769\n",
      "loss: 668.8035460995479\n",
      "loss: 662.3884634791674\n",
      "loss: 654.9287002665726\n",
      "loss: 646.1395263078764\n",
      "loss: 636.1312038563699\n",
      "loss: 626.1323380596333\n",
      "test loss: 487.8963104647752\n",
      "STEP:  37\n",
      "loss: 617.5749114539868\n",
      "loss: 609.8899435624156\n",
      "loss: 602.1617386918107\n",
      "loss: 593.7317185297209\n",
      "loss: 585.0988452130973\n",
      "loss: 577.7121038402028\n",
      "loss: 571.7547891520254\n",
      "loss: 566.3216678342145\n",
      "loss: 560.51610701976\n",
      "loss: 554.0804722286231\n",
      "loss: 547.1826054172288\n",
      "loss: 540.364397106163\n",
      "loss: 534.1532496858318\n",
      "loss: 528.7410313834561\n",
      "loss: 523.8629544911529\n",
      "loss: 519.4824959041714\n",
      "loss: 515.4144698276928\n",
      "loss: 511.62985159980343\n",
      "loss: 508.07416477109797\n",
      "loss: 504.6819575475861\n",
      "test loss: 383.99102340979624\n",
      "STEP:  38\n",
      "loss: 501.43586900511303\n",
      "loss: 498.2809238986612\n",
      "loss: 495.2280586488038\n",
      "loss: 492.233967309923\n",
      "loss: 489.31057213831747\n",
      "loss: 486.416141187444\n",
      "loss: 483.56101294202284\n",
      "loss: 480.7016986342253\n",
      "loss: 477.84760702938297\n",
      "loss: 474.9520622757082\n",
      "loss: 472.022240891808\n",
      "loss: 469.00174436951846\n",
      "loss: 465.89293150305645\n",
      "loss: 462.6134453055221\n",
      "loss: 459.18044028910305\n",
      "loss: 455.59810140805064\n",
      "loss: 451.9970159221003\n",
      "loss: 448.45114784599565\n",
      "loss: 444.9213696784109\n",
      "loss: 441.4618697596615\n",
      "test loss: 325.7058815201608\n",
      "STEP:  39\n",
      "loss: 438.11188125176636\n",
      "loss: 434.8819164665486\n",
      "loss: 431.78655962403906\n",
      "loss: 428.81416037934326\n",
      "loss: 425.95892376724896\n",
      "loss: 423.1968672768333\n",
      "loss: 420.514472226436\n",
      "loss: 417.8862486276917\n",
      "loss: 415.29871241494493\n",
      "loss: 412.7297173071814\n",
      "loss: 410.16963200149354\n",
      "loss: 407.60055896932624\n",
      "loss: 405.01756395285076\n",
      "loss: 402.4051503097643\n",
      "loss: 399.760204767807\n",
      "loss: 397.06594537672845\n",
      "loss: 394.3160762019888\n",
      "loss: 391.49163215406514\n",
      "loss: 388.5820684473725\n",
      "loss: 385.57020661878227\n",
      "test loss: 274.87981399081923\n",
      "STEP:  40\n",
      "loss: 382.4422834344026\n",
      "loss: 379.18202342415736\n",
      "loss: 375.752794152086\n",
      "loss: 372.12257647938196\n",
      "loss: 368.1216353144233\n",
      "loss: 363.58719757333597\n",
      "loss: 358.390989668353\n",
      "loss: 352.10329134437814\n",
      "loss: 344.7965880184047\n",
      "loss: 335.8428015269874\n",
      "loss: 438.747022716646\n",
      "loss: 433.67026402556974\n",
      "loss: 421.3825062888095\n",
      "loss: 402.9122382515906\n",
      "loss: 371.2015947830154\n",
      "loss: 347.4994785285481\n",
      "loss: 347.10301759478114\n",
      "loss: 345.39142887831883\n",
      "loss: 343.6760147549755\n",
      "loss: 341.95745657007296\n",
      "test loss: 249.3011462256869\n",
      "STEP:  41\n",
      "loss: 340.23699818368203\n",
      "loss: 338.51656114777734\n",
      "loss: 742.2126016108806\n",
      "loss: 718.7339485909176\n",
      "loss: 702.3128355729361\n",
      "loss: 662.2366289097772\n",
      "loss: 637.2186347971448\n",
      "loss: 622.9311577789798\n",
      "loss: 610.9763834783798\n",
      "loss: 600.0113645264855\n",
      "loss: 589.7902248208308\n",
      "loss: 580.1835346197279\n",
      "loss: 571.0945810651996\n",
      "loss: 562.4482021347768\n",
      "loss: 554.1853139526619\n",
      "loss: 546.2586826266624\n",
      "loss: 538.6300467543591\n",
      "loss: 531.267861674388\n",
      "loss: 524.145688452064\n",
      "loss: 517.241158728992\n",
      "test loss: 444.7569953249338\n",
      "STEP:  42\n",
      "loss: 510.53515544956014\n",
      "loss: 504.01105472750277\n",
      "loss: 497.65437524127975\n",
      "loss: 491.45234882423017\n",
      "loss: 485.39365679435394\n",
      "loss: 479.46818806944606\n",
      "loss: 473.66684830244685\n",
      "loss: 467.98139733799644\n",
      "loss: 462.4042534192528\n",
      "loss: 456.9284390986126\n",
      "loss: 451.5473099489496\n",
      "loss: 446.2547211706733\n",
      "loss: 441.0449839867214\n",
      "loss: 435.9129569596484\n",
      "loss: 430.8540591150612\n",
      "loss: 425.8642883474546\n",
      "loss: 420.9410607844581\n",
      "loss: 416.0838921367275\n",
      "loss: 411.29457093608585\n",
      "loss: 406.57816686721577\n",
      "test loss: 323.3670079367416\n",
      "STEP:  43\n",
      "loss: 401.9415964994131\n",
      "loss: 397.3936605179521\n",
      "loss: 392.9435292211078\n",
      "loss: 388.59960566467856\n",
      "loss: 384.3681658953821\n",
      "loss: 380.25217541794467\n",
      "loss: 376.250449580842\n",
      "loss: 372.3572497998648\n",
      "loss: 368.5627430425257\n",
      "loss: 364.8532639029577\n",
      "loss: 361.2120835751074\n",
      "loss: 357.6194420772644\n",
      "loss: 354.0528503167001\n",
      "loss: 350.4865216767533\n",
      "loss: 346.8913743612363\n",
      "loss: 343.2350072676481\n",
      "loss: 339.48437027251424\n",
      "loss: 335.61431543310243\n",
      "loss: 331.6284797740811\n",
      "loss: 327.59505335284155\n",
      "test loss: 236.81740467863514\n",
      "STEP:  44\n",
      "loss: 323.6637749932757\n",
      "loss: 320.00665328465266\n",
      "loss: 316.71279050028534\n",
      "loss: 313.7706496341797\n",
      "loss: 311.1242213122676\n",
      "loss: 308.71665683909777\n",
      "loss: 306.5023401667547\n",
      "loss: 304.44648635479405\n",
      "loss: 302.52229871635643\n",
      "loss: 300.70867706847395\n",
      "loss: 298.9886987767721\n",
      "loss: 297.3485808469114\n",
      "loss: 295.77700744114514\n",
      "loss: 294.26462865397303\n",
      "loss: 292.80370578141475\n",
      "loss: 291.3878261515346\n",
      "loss: 290.01168109404256\n",
      "loss: 288.6708759546041\n",
      "loss: 287.3617762225762\n",
      "loss: 286.0813605678374\n",
      "test loss: 204.53766748816233\n",
      "STEP:  45\n",
      "loss: 284.8271143454358\n",
      "loss: 283.59689958941414\n",
      "loss: 282.3888942465021\n",
      "loss: 281.20146249504114\n",
      "loss: 280.03315226782485\n",
      "loss: 278.88254482617737\n",
      "loss: 277.74833703205724\n",
      "loss: 276.62913155806774\n",
      "loss: 275.52364475684664\n",
      "loss: 274.4303747110609\n",
      "loss: 273.3479992294079\n",
      "loss: 272.2748182081677\n",
      "loss: 271.2094782873146\n",
      "loss: 270.14998489838445\n",
      "loss: 269.0950157636668\n",
      "loss: 268.04206485395963\n",
      "loss: 266.9898580655071\n",
      "loss: 265.9345972964164\n",
      "loss: 264.8750961677208\n",
      "loss: 263.8038075724206\n",
      "test loss: 186.3522530149016\n",
      "STEP:  46\n",
      "loss: 262.71878382955606\n",
      "loss: 261.5860898534941\n",
      "loss: 260.3836874280541\n",
      "loss: 259.0237321850512\n",
      "loss: 257.7042232668035\n",
      "loss: 256.319161746027\n",
      "loss: 254.8369666928101\n",
      "loss: 253.19900937892666\n",
      "loss: 251.3689148258359\n",
      "loss: 249.22866207007775\n",
      "loss: 246.60275325110607\n",
      "loss: 243.1299476430906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 238.3026696213173\n",
      "loss: 232.32185600927878\n",
      "loss: 227.8453697801844\n",
      "loss: 225.05371010294374\n",
      "loss: 223.0578048044716\n",
      "loss: 221.2221647975236\n",
      "loss: 219.59839218649446\n",
      "loss: 218.3111226186804\n",
      "test loss: 147.0937335390986\n",
      "STEP:  47\n",
      "loss: 217.21950220928025\n",
      "loss: 216.179256710257\n",
      "loss: 215.22488227584802\n",
      "loss: 214.32459713704455\n",
      "loss: 213.49105351170437\n",
      "loss: 212.68241757248333\n",
      "loss: 211.91388089963047\n",
      "loss: 211.16523443238495\n",
      "loss: 210.44679937812987\n",
      "loss: 209.73872731761887\n",
      "loss: 209.05066347025877\n",
      "loss: 208.36985503113897\n",
      "loss: 207.70405888174145\n",
      "loss: 207.0414126241713\n",
      "loss: 206.3889534682061\n",
      "loss: 205.73748906347194\n",
      "loss: 205.0931552909738\n",
      "loss: 204.44753861521795\n",
      "loss: 203.80627915973378\n",
      "loss: 203.16205692047757\n",
      "test loss: 134.1547597162959\n",
      "STEP:  48\n",
      "loss: 202.52010071693812\n",
      "loss: 201.87359960403526\n",
      "loss: 201.22751579328707\n",
      "loss: 200.5753206552901\n",
      "loss: 199.92172144610586\n",
      "loss: 199.25993972270146\n",
      "loss: 198.59438223674104\n",
      "loss: 197.9176105148119\n",
      "loss: 197.2335087925867\n",
      "loss: 196.53315451218302\n",
      "loss: 195.8194620414963\n",
      "loss: 195.07935586228862\n",
      "loss: 194.31349105201855\n",
      "loss: 193.48519657965593\n",
      "loss: 192.5803423195865\n",
      "loss: 191.64798237819642\n",
      "loss: 190.67927395308604\n",
      "loss: 189.75265195376193\n",
      "loss: 188.90581185084721\n",
      "loss: 188.13163833285998\n",
      "test loss: 124.22797376523663\n",
      "STEP:  49\n",
      "loss: 187.38526965012628\n",
      "loss: 186.67959412939118\n",
      "loss: 186.02442849557585\n",
      "loss: 185.39520606049425\n",
      "loss: 184.7840213513759\n",
      "loss: 184.1950186584358\n",
      "loss: 183.62570631457868\n",
      "loss: 183.06696001905726\n",
      "loss: 182.5189174928075\n",
      "loss: 181.97687760296753\n",
      "loss: 181.44007682212734\n",
      "loss: 180.9050300053338\n",
      "loss: 180.37140762076723\n",
      "loss: 179.837982760343\n",
      "loss: 179.30398452204608\n",
      "loss: 178.76881696927074\n",
      "loss: 178.23186012657825\n",
      "loss: 177.69387660337335\n",
      "loss: 177.15394045082715\n",
      "loss: 176.61311494538725\n",
      "test loss: 118.5399582596028\n",
      "STEP:  50\n",
      "loss: 176.0704915297062\n",
      "loss: 175.52790499155552\n",
      "loss: 174.98412150237502\n",
      "loss: 174.4409149086897\n",
      "loss: 173.89695807058314\n",
      "loss: 173.35432494466238\n",
      "loss: 172.81134932950852\n",
      "loss: 172.26987687598233\n",
      "loss: 171.72814966821431\n",
      "loss: 171.1880717607951\n",
      "loss: 170.64768206015765\n",
      "loss: 170.10870555232728\n",
      "loss: 169.5691807309365\n",
      "loss: 169.0307126015501\n",
      "loss: 168.4913163080201\n",
      "loss: 167.95239066034864\n",
      "loss: 167.4119927866056\n",
      "loss: 166.8712656654254\n",
      "loss: 166.3283427287951\n",
      "loss: 165.78407482672134\n",
      "test loss: 113.07088251325449\n",
      "STEP:  51\n",
      "loss: 165.23678089915612\n",
      "loss: 164.68716227719366\n",
      "loss: 164.13419145999887\n",
      "loss: 163.58039651676066\n",
      "loss: 163.02169777922072\n",
      "loss: 162.4709933444638\n",
      "loss: 161.91916118743583\n",
      "loss: 161.3803292875926\n",
      "loss: 160.80451583522225\n",
      "loss: 160.27729512428638\n",
      "loss: 159.72305677101542\n",
      "loss: 159.1732670838993\n",
      "loss: 158.63256956989625\n",
      "loss: 158.09558558058868\n",
      "loss: 157.5741097235442\n",
      "loss: 157.04451621373255\n",
      "loss: 156.50848627860768\n",
      "loss: 155.97794068233364\n",
      "loss: 155.46085402229198\n",
      "loss: 154.9444408064803\n",
      "test loss: 108.16920599796237\n",
      "STEP:  52\n",
      "loss: 154.45548578329473\n",
      "loss: 153.9230805754806\n",
      "loss: 153.44959029099198\n",
      "loss: 152.9735447657079\n",
      "loss: 152.4566318472442\n",
      "loss: 151.96414893304484\n",
      "loss: 151.4654137240775\n",
      "loss: 150.97884151503325\n",
      "loss: 150.4198395039427\n",
      "loss: 149.93116836307922\n",
      "loss: 149.4410730628157\n",
      "loss: 148.8719755430963\n",
      "loss: 148.3763590542598\n",
      "loss: 147.85128241896817\n",
      "loss: 147.27137186976825\n",
      "loss: 146.77379263312673\n",
      "loss: 146.1468221539229\n",
      "loss: 145.65499454103693\n",
      "loss: 145.1313779758554\n",
      "loss: 144.60570258130832\n",
      "test loss: 104.63135345020866\n",
      "STEP:  53\n",
      "loss: 144.08647095658102\n",
      "loss: 143.5810984525238\n",
      "loss: 143.08863504322153\n",
      "loss: 142.6088898740151\n",
      "loss: 142.14223092318616\n",
      "loss: 141.6896625829475\n",
      "loss: 141.25143293630964\n",
      "loss: 140.82738380359635\n",
      "loss: 140.41602575059366\n",
      "loss: 140.01795594601464\n",
      "loss: 139.63354568560763\n",
      "loss: 139.26101426820955\n",
      "loss: 138.88321810339733\n",
      "loss: 138.55145481199827\n",
      "loss: 138.20921081334794\n",
      "loss: 137.8781070383909\n",
      "loss: 137.55491599763056\n",
      "loss: 137.24074705802718\n",
      "loss: 136.93781402601746\n",
      "loss: 136.62920695368854\n",
      "test loss: 102.62518681650916\n",
      "STEP:  54\n",
      "loss: 136.2903400531138\n",
      "loss: 135.98263557107677\n",
      "loss: 135.68126244005376\n",
      "loss: 135.38612027679403\n",
      "loss: 135.0953379262404\n",
      "loss: 134.8084220531434\n",
      "loss: 134.52484443768915\n",
      "loss: 134.24668236897443\n",
      "loss: 133.97226926283756\n",
      "loss: 133.70123933670789\n",
      "loss: 133.4318408211\n",
      "loss: 133.15579073968235\n",
      "loss: 132.89050509783135\n",
      "loss: 132.61419831242466\n",
      "loss: 132.35185278821263\n",
      "loss: 132.09132021384724\n",
      "loss: 131.83413528086777\n",
      "loss: 131.58089502503586\n",
      "loss: 131.3301362065449\n",
      "loss: 131.08119198268463\n",
      "test loss: 101.0184553249042\n",
      "STEP:  55\n",
      "loss: 130.83157678536944\n",
      "loss: 130.50536548525284\n",
      "loss: 130.26812969259396\n",
      "loss: 130.0334351665748\n",
      "loss: 129.79931546130746\n",
      "loss: 129.56362432348988\n",
      "loss: 129.32603074267178\n",
      "loss: 129.08236139507176\n",
      "loss: 128.8334727196113\n",
      "loss: 128.55523774931694\n",
      "loss: 128.24405260021865\n",
      "loss: 127.93491680768516\n",
      "loss: 127.62361809283898\n",
      "loss: 127.31045266496088\n",
      "loss: 126.99338654203896\n",
      "loss: 126.6236355269669\n",
      "loss: 126.17611591451407\n",
      "loss: 125.70514848885047\n",
      "loss: 125.21171879256174\n",
      "loss: 124.69900120369985\n",
      "test loss: 98.40778706204533\n",
      "STEP:  56\n",
      "loss: 124.19964254797688\n",
      "loss: 123.72196948133033\n",
      "loss: 123.28496630025775\n",
      "loss: 122.88613528969113\n",
      "loss: 122.52981990179505\n",
      "loss: 122.2058832091493\n",
      "loss: 121.91198873581345\n",
      "loss: 121.6396633847231\n",
      "loss: 121.38686273441968\n",
      "loss: 121.14696679875472\n",
      "loss: 120.91980759414042\n",
      "loss: 120.70174172251733\n",
      "loss: 120.49274886254373\n",
      "loss: 120.28922065519741\n",
      "loss: 120.09158123460898\n",
      "loss: 119.89648278985919\n",
      "loss: 119.70419375993768\n",
      "loss: 119.51124226060499\n",
      "loss: 119.31692853336902\n",
      "loss: 119.11661269248111\n",
      "test loss: 97.98004135321361\n",
      "STEP:  57\n",
      "loss: 118.90607404544896\n",
      "loss: 118.67620019359273\n",
      "loss: 118.42254778400022\n",
      "loss: 118.15775286781673\n",
      "loss: 117.95211695294202\n",
      "loss: 117.79947146449362\n",
      "loss: 117.66960459211633\n",
      "loss: 117.54778392334768\n",
      "loss: 117.42042832029503\n",
      "loss: 117.27622983194547\n",
      "loss: 117.15903472548355\n",
      "loss: 117.05410331648554\n",
      "loss: 116.94911227702579\n",
      "loss: 116.84946648886942\n",
      "loss: 116.75424125844137\n",
      "loss: 116.6643828375479\n",
      "loss: 116.57615952859436\n",
      "loss: 116.49206203091492\n",
      "loss: 116.41057706170452\n",
      "loss: 116.29329614004997\n",
      "test loss: 97.63142545533337\n",
      "STEP:  58\n",
      "loss: 116.21134702481544\n",
      "loss: 116.126106175569\n",
      "loss: 116.02499778116795\n",
      "loss: 115.90621588840143\n",
      "loss: 115.76391647943231\n",
      "loss: 115.64402175637262\n",
      "loss: 115.52787594258933\n",
      "loss: 115.41213734625637\n",
      "loss: 115.29568515526536\n",
      "loss: 115.17902018348629\n",
      "loss: 115.06074613255565\n",
      "loss: 114.94137963484357\n",
      "loss: 114.81811872666437\n",
      "loss: 114.68964358502932\n",
      "loss: 114.51952600339877\n",
      "loss: 114.3405716404162\n",
      "loss: 113.32711310769602\n",
      "loss: 113.26256762657151\n",
      "loss: 113.17930066602564\n",
      "loss: 113.09915346068983\n",
      "test loss: 95.94878448128907\n",
      "STEP:  59\n",
      "loss: 113.0189774091238\n",
      "loss: 112.93637047767078\n",
      "loss: 112.85040776508983\n",
      "loss: 112.76299203027618\n",
      "loss: 112.6749109554313\n",
      "loss: 112.58658624023225\n",
      "loss: 112.49822226789529\n",
      "loss: 112.41024530112963\n",
      "loss: 112.32262020834322\n",
      "loss: 112.23572614258765\n",
      "loss: 112.1494104970171\n",
      "loss: 112.06403361045001\n",
      "loss: 111.97937466412752\n",
      "loss: 111.89580699900837\n",
      "loss: 111.81304528734537\n",
      "loss: 111.73147511102341\n",
      "loss: 111.65072289657641\n",
      "loss: 111.57106145783138\n",
      "loss: 111.4919766512815\n",
      "loss: 111.41344574464037\n",
      "test loss: 94.5968041925922\n",
      "STEP:  60\n",
      "loss: 111.33457119161615\n",
      "loss: 111.25587033258937\n",
      "loss: 111.17270343258365\n",
      "loss: 111.08752629935134\n",
      "loss: 111.00909579285423\n",
      "loss: 110.9322904165543\n",
      "loss: 110.8602850433123\n",
      "loss: 110.78927616014813\n",
      "loss: 110.71365595604165\n",
      "loss: 110.63401691893021\n",
      "loss: 110.56127945769468\n",
      "loss: 110.48874202408356\n",
      "loss: 110.41744585713836\n",
      "loss: 110.34686865477414\n",
      "loss: 110.2773524589094\n",
      "loss: 110.20883803037535\n",
      "loss: 110.14153122624654\n",
      "loss: 110.0754487462711\n",
      "loss: 110.01072969290145\n",
      "loss: 109.94744416546327\n",
      "test loss: 93.45513713167833\n",
      "STEP:  61\n",
      "loss: 109.88572076643179\n",
      "loss: 109.825649213178\n",
      "loss: 109.76735156133522\n",
      "loss: 109.7109129883662\n",
      "loss: 109.65643591612809\n",
      "loss: 109.60397732877462\n",
      "loss: 109.55360466660782\n",
      "loss: 109.50532862530312\n",
      "loss: 109.45917408175275\n",
      "loss: 109.41509754694799\n",
      "loss: 109.37308651979923\n",
      "loss: 109.33304495781333\n",
      "loss: 109.29494198343957\n",
      "loss: 109.25863192972699\n",
      "loss: 109.22409659543459\n",
      "loss: 109.19112912072727\n",
      "loss: 109.15977069190886\n",
      "loss: 109.1296926150609\n",
      "loss: 109.10104914542612\n",
      "loss: 109.0731147433495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 92.89491529259408\n",
      "STEP:  62\n",
      "loss: 109.03567633133119\n",
      "loss: 109.01081788982208\n",
      "loss: 108.99007917902568\n",
      "loss: 108.96988608032648\n",
      "loss: 108.94990596418283\n",
      "loss: 108.9300804073361\n",
      "loss: 108.91021255399693\n",
      "loss: 108.88558477450826\n",
      "loss: 108.8551783833257\n",
      "loss: 108.83067711191433\n",
      "loss: 108.80610835590291\n",
      "loss: 108.78200939876444\n",
      "loss: 108.75662927228578\n",
      "loss: 108.73147643933424\n",
      "loss: 108.70482690174012\n",
      "loss: 108.6729198651242\n",
      "loss: 108.64834085973747\n",
      "loss: 108.62225440413617\n",
      "loss: 108.59331492625354\n",
      "loss: 108.56741175167718\n",
      "test loss: 92.31638182975625\n",
      "STEP:  63\n",
      "loss: 108.54466767958526\n",
      "loss: 108.51882399714522\n",
      "loss: 108.49419069811098\n",
      "loss: 108.47002569382201\n",
      "loss: 108.4449770636369\n",
      "loss: 108.41962739167784\n",
      "loss: 108.39372133752448\n",
      "loss: 108.36769905783333\n",
      "loss: 108.341283452979\n",
      "loss: 108.31481693450158\n",
      "loss: 108.28802045515074\n",
      "loss: 108.26119700759641\n",
      "loss: 108.23403971063628\n",
      "loss: 108.2068822165943\n",
      "loss: 108.17922132534895\n",
      "loss: 108.15155148646103\n",
      "loss: 108.1226219962978\n",
      "loss: 108.09365543994336\n",
      "loss: 108.06403703818062\n",
      "loss: 108.03615994978745\n",
      "test loss: 91.75388804584608\n",
      "STEP:  64\n",
      "loss: 108.00814777594879\n",
      "loss: 107.98085447564343\n",
      "loss: 107.95206530564211\n",
      "loss: 107.92397325345847\n",
      "loss: 107.89429641635351\n",
      "loss: 107.86653393869764\n",
      "loss: 107.83698895627303\n",
      "loss: 107.80800749641384\n",
      "loss: 107.7779661132036\n",
      "loss: 107.74930625496845\n",
      "loss: 107.71888005564145\n",
      "loss: 107.68911890596193\n",
      "loss: 107.65913428279971\n",
      "loss: 107.62979389819436\n",
      "loss: 107.6002293656513\n",
      "loss: 107.57112232932558\n",
      "loss: 107.5417852063045\n",
      "loss: 107.51288318266724\n",
      "loss: 107.48373866368398\n",
      "loss: 107.45508367564223\n",
      "test loss: 91.12481764080107\n",
      "STEP:  65\n",
      "loss: 107.4261720340386\n",
      "loss: 107.39782935877594\n",
      "loss: 107.36925593125973\n",
      "loss: 107.34136594273814\n",
      "loss: 107.31335389040377\n",
      "loss: 107.28601200982826\n",
      "loss: 107.25860941275526\n",
      "loss: 107.23179962934466\n",
      "loss: 107.20494468244358\n",
      "loss: 107.17867241030288\n",
      "loss: 107.15241191150635\n",
      "loss: 107.12661164773861\n",
      "loss: 107.10065808883492\n",
      "loss: 107.07356560314209\n",
      "loss: 107.04326746563854\n",
      "loss: 107.01307132025654\n",
      "loss: 106.98683233345503\n",
      "loss: 106.95730645758101\n",
      "loss: 106.93049453008769\n",
      "loss: 106.90620181667714\n",
      "test loss: 90.48381096451374\n",
      "STEP:  66\n",
      "loss: 106.88174405353621\n",
      "loss: 106.85751856593653\n",
      "loss: 106.83302622089461\n",
      "loss: 106.80914454486057\n",
      "loss: 106.7854340494098\n",
      "loss: 106.76257941909303\n",
      "loss: 106.73995701264481\n",
      "loss: 106.71785373914872\n",
      "loss: 106.69572344643089\n",
      "loss: 106.67366098127135\n",
      "loss: 106.64547940010291\n",
      "loss: 106.62028482023594\n",
      "loss: 106.5978821967619\n",
      "loss: 106.5730619428828\n",
      "loss: 106.54646492600811\n",
      "loss: 106.51988032917166\n",
      "loss: 106.49236688976413\n",
      "loss: 106.46397571113965\n",
      "loss: 106.43511030171746\n",
      "loss: 106.40580131330833\n",
      "test loss: 89.81757913206788\n",
      "STEP:  67\n",
      "loss: 106.3761039192697\n",
      "loss: 106.34581928536616\n",
      "loss: 106.26419479277183\n",
      "loss: 106.23432796183444\n",
      "loss: 106.20635306195952\n",
      "loss: 106.17767107179115\n",
      "loss: 106.14863998229734\n",
      "loss: 106.11780401241452\n",
      "loss: 106.08764567827062\n",
      "loss: 106.05478761381742\n",
      "loss: 106.02667726922822\n",
      "loss: 105.99551262836326\n",
      "loss: 105.96461534929392\n",
      "loss: 105.93319081856126\n",
      "loss: 105.90162031133902\n",
      "loss: 105.86928415191201\n",
      "loss: 105.81837613927328\n",
      "loss: 105.7862838973285\n",
      "loss: 105.75287499773496\n",
      "loss: 105.72008703223378\n",
      "test loss: 88.69209523497689\n",
      "STEP:  68\n",
      "loss: 105.68664092702684\n",
      "loss: 105.65353113609588\n",
      "loss: 105.61992046230168\n",
      "loss: 105.58690224338328\n",
      "loss: 105.55383377392297\n",
      "loss: 105.52140568359424\n",
      "loss: 105.4887678619873\n",
      "loss: 105.45678898309885\n",
      "loss: 105.42483827358934\n",
      "loss: 105.39349510179989\n",
      "loss: 105.35902480434221\n",
      "loss: 105.33039544877289\n",
      "loss: 105.29948626167209\n",
      "loss: 105.26884890104874\n",
      "loss: 105.23526250579167\n",
      "loss: 105.20044273981782\n",
      "loss: 105.16429905658806\n",
      "loss: 105.128220238605\n",
      "loss: 105.09195653766686\n",
      "loss: 105.05609586261183\n",
      "test loss: 87.62417257632232\n",
      "STEP:  69\n",
      "loss: 105.0175413527376\n",
      "loss: 104.98473915642423\n",
      "loss: 104.94867481729977\n",
      "loss: 104.91257630541553\n",
      "loss: 104.87571269675293\n",
      "loss: 104.83890046693996\n",
      "loss: 104.80323186555009\n",
      "loss: 104.76847817793066\n",
      "loss: 104.73394035046189\n",
      "loss: 104.69943423020192\n",
      "loss: 104.6598183508454\n",
      "loss: 104.62963953442107\n",
      "loss: 104.59815983875609\n",
      "loss: 104.5662993883212\n",
      "loss: 104.53470237320315\n",
      "loss: 104.50360563569036\n",
      "loss: 104.47306699474497\n",
      "loss: 104.44304458185243\n",
      "loss: 104.41345374929074\n",
      "loss: 104.38417578086059\n",
      "test loss: 86.56895531819835\n",
      "STEP:  70\n",
      "loss: 104.35511338970416\n",
      "loss: 104.32607948645536\n",
      "loss: 104.29706363450282\n",
      "loss: 104.26031267463254\n",
      "loss: 104.22953761473514\n",
      "loss: 104.20033715855486\n",
      "loss: 104.17082361509085\n",
      "loss: 104.14146860060167\n",
      "loss: 104.11167142612814\n",
      "loss: 104.08208092718344\n",
      "loss: 104.05208894306044\n",
      "loss: 104.02277410647544\n",
      "loss: 103.99347885508958\n",
      "loss: 103.96498808784706\n",
      "loss: 103.93651299637065\n",
      "loss: 103.90853044214866\n",
      "loss: 103.88042397376265\n",
      "loss: 103.85264002387136\n",
      "loss: 103.82465068891415\n",
      "loss: 103.79692623465198\n",
      "test loss: 85.59083264588342\n",
      "STEP:  71\n",
      "loss: 103.76890576320594\n",
      "loss: 103.74118706246632\n",
      "loss: 103.71314519129572\n",
      "loss: 103.68555720446595\n",
      "loss: 103.65777181124768\n",
      "loss: 103.6306168512991\n",
      "loss: 103.60336775461212\n",
      "loss: 103.57668110319972\n",
      "loss: 103.54972608608708\n",
      "loss: 103.52289503209902\n",
      "loss: 103.49526028626155\n",
      "loss: 103.46293799055394\n",
      "loss: 103.40722583715107\n",
      "loss: 103.38213027678921\n",
      "loss: 103.35834479292436\n",
      "loss: 103.3344893854964\n",
      "loss: 103.311055432144\n",
      "loss: 103.28759453441567\n",
      "loss: 103.26450873739174\n",
      "loss: 103.24137652580097\n",
      "test loss: 84.89581815047518\n",
      "STEP:  72\n",
      "loss: 103.2185599928579\n",
      "loss: 103.19566767966701\n",
      "loss: 103.17304812940598\n",
      "loss: 103.1498188934324\n",
      "loss: 103.12594326637708\n",
      "loss: 103.10278139136577\n",
      "loss: 103.08087150077846\n",
      "loss: 103.05913884560212\n",
      "loss: 103.03794977343655\n",
      "loss: 103.01669218110602\n",
      "loss: 102.9955002925913\n",
      "loss: 102.9738098988871\n",
      "loss: 102.95261314357342\n",
      "loss: 102.93155948452926\n",
      "loss: 102.91106145984457\n",
      "loss: 102.89056700102414\n",
      "loss: 102.86974717616316\n",
      "loss: 102.84905282890692\n",
      "loss: 102.82830661823637\n",
      "loss: 102.80714408238804\n",
      "test loss: 84.57634580475887\n",
      "STEP:  73\n",
      "loss: 102.78576782206007\n",
      "loss: 102.76640953224062\n",
      "loss: 102.74750322480153\n",
      "loss: 102.72916154988904\n",
      "loss: 102.7105445048101\n",
      "loss: 102.69242761013639\n",
      "loss: 102.67435082525627\n",
      "loss: 102.65679069432281\n",
      "loss: 102.6392041662153\n",
      "loss: 102.6222072317567\n",
      "loss: 102.60527793440592\n",
      "loss: 102.58845766708902\n",
      "loss: 102.56881799028469\n",
      "loss: 102.55046651848832\n",
      "loss: 102.53284290387266\n",
      "loss: 102.51606203285355\n",
      "loss: 102.50060572790215\n",
      "loss: 102.48554514105999\n",
      "loss: 102.47025389840597\n",
      "loss: 102.45514746268086\n",
      "test loss: 84.34551466192744\n",
      "STEP:  74\n",
      "loss: 102.43999105450666\n",
      "loss: 102.42543988058924\n",
      "loss: 102.41107585466294\n",
      "loss: 102.39716136025658\n",
      "loss: 102.38329929683778\n",
      "loss: 102.36966748631697\n",
      "loss: 102.35583688629977\n",
      "loss: 102.34156698215793\n",
      "loss: 102.32685870243682\n",
      "loss: 102.31199948296184\n",
      "loss: 102.29529154588718\n",
      "loss: 102.2815896910405\n",
      "loss: 102.26766309965868\n",
      "loss: 102.25365430934671\n",
      "loss: 102.23930291840132\n",
      "loss: 102.2245149468759\n",
      "loss: 102.20929088740577\n",
      "loss: 102.19524573021482\n",
      "loss: 102.18199940869611\n",
      "loss: 102.16833476972982\n",
      "test loss: 84.1959706865542\n",
      "STEP:  75\n",
      "loss: 102.15509284705823\n",
      "loss: 102.14188526999843\n",
      "loss: 102.12876194123803\n",
      "loss: 102.11551420327181\n",
      "loss: 102.10204457180288\n",
      "loss: 102.08801048671522\n",
      "loss: 102.07500057797543\n",
      "loss: 102.0621844470379\n",
      "loss: 102.04962598176233\n",
      "loss: 102.03703185780212\n",
      "loss: 102.0246518010627\n",
      "loss: 102.01220191094335\n",
      "loss: 101.99997509167994\n",
      "loss: 101.98768099912078\n",
      "loss: 101.97564022336825\n",
      "loss: 101.96354431629557\n",
      "loss: 101.95169777332553\n",
      "loss: 101.93980396496525\n",
      "loss: 101.92813771505922\n",
      "loss: 101.91642521606606\n",
      "test loss: 84.10978378908193\n",
      "STEP:  76\n",
      "loss: 101.90491937084224\n",
      "loss: 101.89336165853094\n",
      "loss: 101.88199421956556\n",
      "loss: 101.87057002418474\n",
      "loss: 101.85933138663009\n",
      "loss: 101.84804071934883\n",
      "loss: 101.83694406670875\n",
      "loss: 101.82579797943069\n",
      "loss: 101.81484617513179\n",
      "loss: 101.80380013534047\n",
      "loss: 101.79288144062701\n",
      "loss: 101.78179058456844\n",
      "loss: 101.77091895470765\n",
      "loss: 101.7602889843619\n",
      "loss: 101.74979935474975\n",
      "loss: 101.73913633838386\n",
      "loss: 101.72867495310247\n",
      "loss: 101.7182936809905\n",
      "loss: 101.7078999002813\n",
      "loss: 101.69734986629925\n",
      "test loss: 84.06708402045163\n",
      "STEP:  77\n",
      "loss: 101.68704010450077\n",
      "loss: 101.67673335733511\n",
      "loss: 101.66635245376294\n",
      "loss: 101.65588966208612\n",
      "loss: 101.64559174147351\n",
      "loss: 101.63512064876114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 101.62417714439951\n",
      "loss: 101.61335912416128\n",
      "loss: 101.60298893127626\n",
      "loss: 101.592418415686\n",
      "loss: 101.58129529454088\n",
      "loss: 101.57078209084597\n",
      "loss: 101.56080437802966\n",
      "loss: 101.55077013321504\n",
      "loss: 101.54050135163911\n",
      "loss: 101.53020269461034\n",
      "loss: 101.52014153853521\n",
      "loss: 101.51008460653581\n",
      "loss: 101.49986552063933\n",
      "loss: 101.489675351497\n",
      "test loss: 84.04409667349633\n",
      "STEP:  78\n",
      "loss: 101.47930014183127\n",
      "loss: 101.4684001170811\n",
      "loss: 101.45724936451276\n",
      "loss: 101.44715137873666\n",
      "loss: 101.43692802785947\n",
      "loss: 101.42649232844856\n",
      "loss: 101.41662939851103\n",
      "loss: 101.40647791936453\n",
      "loss: 101.39647816675733\n",
      "loss: 101.38663660528059\n",
      "loss: 101.37683780829478\n",
      "loss: 101.36649295960817\n",
      "loss: 101.35669287522175\n",
      "loss: 101.34702115497939\n",
      "loss: 101.33744719266147\n",
      "loss: 101.32768318423948\n",
      "loss: 101.31812343231586\n",
      "loss: 101.30870128201163\n",
      "loss: 101.29932485804099\n",
      "loss: 101.28988479274587\n",
      "test loss: 84.0300879755701\n",
      "STEP:  79\n",
      "loss: 101.28067592733623\n",
      "loss: 101.27152426514306\n",
      "loss: 101.26243259744442\n",
      "loss: 101.25328533709536\n",
      "loss: 101.2442737279736\n",
      "loss: 101.23530107182309\n",
      "loss: 101.22641307582263\n",
      "loss: 101.21750106223641\n",
      "loss: 101.20868016356386\n",
      "loss: 101.19977878954654\n",
      "loss: 101.19079921121063\n",
      "loss: 101.18166820712746\n",
      "loss: 101.17297797429629\n",
      "loss: 101.16456550923533\n",
      "loss: 101.15627601562912\n",
      "loss: 101.14786427148458\n",
      "loss: 101.13962890612406\n",
      "loss: 101.1315528649863\n",
      "loss: 101.1235375502603\n",
      "loss: 101.11542332216099\n",
      "test loss: 84.02490840942386\n",
      "STEP:  80\n",
      "loss: 101.1075594864942\n",
      "loss: 101.09981602910477\n",
      "loss: 101.09212548274195\n",
      "loss: 101.08452183758166\n",
      "loss: 101.07697668921404\n",
      "loss: 101.06944018423069\n",
      "loss: 101.06198374757629\n",
      "loss: 101.05451456138762\n",
      "loss: 101.04670460973011\n",
      "loss: 101.0387903240435\n",
      "loss: 101.03119135187322\n",
      "loss: 101.02351479375231\n",
      "loss: 101.01265535701337\n",
      "loss: 101.0056089017241\n",
      "loss: 100.99845672378147\n",
      "loss: 100.99012618351428\n",
      "loss: 100.9824647461433\n",
      "loss: 100.9745559091623\n",
      "loss: 100.96654006343596\n",
      "loss: 100.95726123550534\n",
      "test loss: 84.06078620007207\n",
      "STEP:  81\n",
      "loss: 100.94894539003202\n",
      "loss: 100.93976467475395\n",
      "loss: 100.9303266980804\n",
      "loss: 100.92076417547537\n",
      "loss: 100.91084119692903\n",
      "loss: 100.90084389707415\n",
      "loss: 100.89042031742008\n",
      "loss: 100.87178309744203\n",
      "loss: 100.8610523576682\n",
      "loss: 100.85014074740036\n",
      "loss: 100.83887644686467\n",
      "loss: 100.82691182208495\n",
      "loss: 100.8140173742227\n",
      "loss: 100.8002247769328\n",
      "loss: 100.78729362363275\n",
      "loss: 100.77389760579115\n",
      "loss: 100.76026813455167\n",
      "loss: 100.74610691631881\n",
      "loss: 100.73204308790632\n",
      "loss: 100.71779331202468\n",
      "test loss: 84.20959270657492\n",
      "STEP:  82\n",
      "loss: 100.70380187375487\n",
      "loss: 100.6896062032608\n",
      "loss: 100.6753879710996\n",
      "loss: 100.66055921623152\n",
      "loss: 100.64436131570598\n",
      "loss: 100.62751775849318\n",
      "loss: 100.60979413660012\n",
      "loss: 100.57877669742247\n",
      "loss: 100.56465095562929\n",
      "loss: 100.55065348776546\n",
      "loss: 100.53628566929531\n",
      "loss: 100.52173166075883\n",
      "loss: 100.50678545131652\n",
      "loss: 100.49174128060497\n",
      "loss: 100.47633262235814\n",
      "loss: 100.46101529974996\n",
      "loss: 100.44548267541286\n",
      "loss: 100.43010306092813\n",
      "loss: 100.41452444804042\n",
      "loss: 100.3990088466605\n",
      "test loss: 84.36428020569352\n",
      "STEP:  83\n",
      "loss: 100.3832448878928\n",
      "loss: 100.36750359821042\n",
      "loss: 100.35150264449562\n",
      "loss: 100.33555214600658\n",
      "loss: 100.31935830125907\n",
      "loss: 100.30323673728515\n",
      "loss: 100.28688207970895\n",
      "loss: 100.27059609039581\n",
      "loss: 100.25407683841156\n",
      "loss: 100.2376102077931\n",
      "loss: 100.22090883119708\n",
      "loss: 100.20429828191389\n",
      "loss: 100.18745624358773\n",
      "loss: 100.17061826988584\n",
      "loss: 100.15353149557457\n",
      "loss: 100.13654834911551\n",
      "loss: 100.11945467995882\n",
      "loss: 100.1023867558383\n",
      "loss: 100.08516597100379\n",
      "loss: 100.06797896285923\n",
      "test loss: 84.65580955132225\n",
      "STEP:  84\n",
      "loss: 100.05050410927313\n",
      "loss: 100.03246874811295\n",
      "loss: 100.01198943283968\n",
      "loss: 99.99423089161598\n",
      "loss: 99.9776795735538\n",
      "loss: 99.96078440405815\n",
      "loss: 99.94402391558204\n",
      "loss: 99.92698831619713\n",
      "loss: 99.91030002894465\n",
      "loss: 99.89351982803751\n",
      "loss: 99.87711119801057\n",
      "loss: 99.86062521231\n",
      "loss: 99.84439045533937\n",
      "loss: 99.82803638828345\n",
      "loss: 99.81187429853469\n",
      "loss: 99.79556325528853\n",
      "loss: 99.7794356314655\n",
      "loss: 99.76312223162523\n",
      "loss: 99.74705331630351\n",
      "loss: 99.73081864129317\n",
      "test loss: 85.04960754792671\n",
      "STEP:  85\n",
      "loss: 99.71486699605127\n",
      "loss: 99.69875238235697\n",
      "loss: 99.68296309502524\n",
      "loss: 99.66702647862759\n",
      "loss: 99.65142460519812\n",
      "loss: 99.63568032052699\n",
      "loss: 99.62026543500018\n",
      "loss: 99.60470613025062\n",
      "loss: 99.5894791189507\n",
      "loss: 99.57411499784722\n",
      "loss: 99.55907931653273\n",
      "loss: 99.54390876148294\n",
      "loss: 99.52907118002268\n",
      "loss: 99.51408638884509\n",
      "loss: 99.49941607121204\n",
      "loss: 99.48462200354697\n",
      "loss: 99.47004055292722\n",
      "loss: 99.45502023265564\n",
      "loss: 99.44043936121169\n",
      "loss: 99.42598801529532\n",
      "test loss: 85.49921763559563\n",
      "STEP:  86\n",
      "loss: 99.41200290065376\n",
      "loss: 99.39771713221606\n",
      "loss: 99.38312059328445\n",
      "loss: 99.36855600896385\n",
      "loss: 99.3542269474566\n",
      "loss: 99.3375722458174\n",
      "loss: 99.32142093189161\n",
      "loss: 99.30733844584108\n",
      "loss: 99.29413309353541\n",
      "loss: 99.27832870942385\n",
      "loss: 99.26550067830154\n",
      "loss: 99.25299926263357\n",
      "loss: 99.23997475107065\n",
      "loss: 99.22715979594474\n",
      "loss: 99.21436890176402\n",
      "loss: 99.20154460345272\n",
      "loss: 99.18913057645233\n",
      "loss: 99.1768100613769\n",
      "loss: 99.16468761755478\n",
      "loss: 99.15250971103558\n",
      "test loss: 86.0130412788806\n",
      "STEP:  87\n",
      "loss: 99.14056333187702\n",
      "loss: 99.12866887354735\n",
      "loss: 99.1170443015958\n",
      "loss: 99.10543038127305\n",
      "loss: 99.09398930927543\n",
      "loss: 99.08251903666876\n",
      "loss: 99.07127062337347\n",
      "loss: 99.06002263489255\n",
      "loss: 99.04888653757959\n",
      "loss: 99.03487390310931\n",
      "loss: 99.01842787364158\n",
      "loss: 99.00627663463915\n",
      "loss: 98.99561250498121\n",
      "loss: 98.98426290331977\n",
      "loss: 98.97258528756602\n",
      "loss: 98.96121092723192\n",
      "loss: 98.94962601423472\n",
      "loss: 98.93802827646776\n",
      "loss: 98.92631017224414\n",
      "loss: 98.91466306561746\n",
      "test loss: 86.5561185752143\n",
      "STEP:  88\n",
      "loss: 98.90288439989263\n",
      "loss: 98.89120775866647\n",
      "loss: 98.87940247678048\n",
      "loss: 98.86771562666141\n",
      "loss: 98.85589212803097\n",
      "loss: 98.8442076455991\n",
      "loss: 98.83238130541858\n",
      "loss: 98.82071182740302\n",
      "loss: 98.8088949849306\n",
      "loss: 98.79725251619153\n",
      "loss: 98.78545810047314\n",
      "loss: 98.77385147578299\n",
      "loss: 98.76208834146762\n",
      "loss: 98.75053853639395\n",
      "loss: 98.73883544156742\n",
      "loss: 98.72735578610218\n",
      "loss: 98.71571998433168\n",
      "loss: 98.70432515811495\n",
      "loss: 98.69277808202986\n",
      "loss: 98.68146481449621\n",
      "test loss: 87.17069772809188\n",
      "STEP:  89\n",
      "loss: 98.66999950759512\n",
      "loss: 98.65876133192569\n",
      "loss: 98.64737416069458\n",
      "loss: 98.63620072513166\n",
      "loss: 98.62488480544656\n",
      "loss: 98.61376976351036\n",
      "loss: 98.6025007584486\n",
      "loss: 98.59142485182217\n",
      "loss: 98.58018855376048\n",
      "loss: 98.56917095886853\n",
      "loss: 98.5580033554339\n",
      "loss: 98.54707686246796\n",
      "loss: 98.53601581638998\n",
      "loss: 98.52519595333975\n",
      "loss: 98.51425185934288\n",
      "loss: 98.5035409475812\n",
      "loss: 98.4927141169742\n",
      "loss: 98.48211185181171\n",
      "loss: 98.47139653484626\n",
      "loss: 98.46089675363285\n",
      "test loss: 87.8218025283152\n",
      "STEP:  90\n",
      "loss: 98.45028705526357\n",
      "loss: 98.4398880224217\n",
      "loss: 98.4293745402007\n",
      "loss: 98.41905153190717\n",
      "loss: 98.40858286796517\n",
      "loss: 98.39822137458088\n",
      "loss: 98.38746729515402\n",
      "loss: 98.37539734103471\n",
      "loss: 98.36209436924855\n",
      "loss: 98.35241941390547\n",
      "loss: 98.3429080032746\n",
      "loss: 98.33333727325832\n",
      "loss: 98.3238660843165\n",
      "loss: 98.31439520399894\n",
      "loss: 98.30507014133548\n",
      "loss: 98.29574591910055\n",
      "loss: 98.28657945834998\n",
      "loss: 98.27742147915474\n",
      "loss: 98.26842885926516\n",
      "loss: 98.25944085933834\n",
      "test loss: 88.46742526957641\n",
      "STEP:  91\n",
      "loss: 98.25062102323346\n",
      "loss: 98.24181663326023\n",
      "loss: 98.23319070648812\n",
      "loss: 98.22457872674435\n",
      "loss: 98.21613983674459\n",
      "loss: 98.20772957618267\n",
      "loss: 98.1995369209491\n",
      "loss: 98.1914189299589\n",
      "loss: 98.1834886601963\n",
      "loss: 98.17560364963035\n",
      "loss: 98.1679416671681\n",
      "loss: 98.1601766486091\n",
      "loss: 98.15270034823774\n",
      "loss: 98.1453368866031\n",
      "loss: 98.13815000874372\n",
      "loss: 98.13104029422085\n",
      "loss: 98.12415639159875\n",
      "loss: 98.11736165597112\n",
      "loss: 98.11075279956202\n",
      "loss: 98.10423092216014\n",
      "test loss: 88.98934102795508\n",
      "STEP:  92\n",
      "loss: 98.0978756687517\n",
      "loss: 98.09160652357427\n",
      "loss: 98.0854906014718\n",
      "loss: 98.07945721260303\n",
      "loss: 98.07356333452444\n",
      "loss: 98.06774432708514\n",
      "loss: 98.06204830573301\n",
      "loss: 98.05640493356817\n",
      "loss: 98.05089686566731\n",
      "loss: 98.04545194135558\n",
      "loss: 98.04024338242874\n",
      "loss: 98.03491849621972\n",
      "loss: 98.03014703338391\n",
      "loss: 98.02520380556874\n",
      "loss: 98.0202295473449\n",
      "loss: 98.01528862256808\n",
      "loss: 98.01048843269572\n",
      "loss: 98.00574661670396\n",
      "loss: 98.0010901533204\n",
      "loss: 97.9964692538322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 89.38823272048471\n",
      "STEP:  93\n",
      "loss: 97.99190691637183\n",
      "loss: 97.98735455514468\n",
      "loss: 97.98277864734652\n",
      "loss: 97.97666775779248\n",
      "loss: 97.97244272981406\n",
      "loss: 97.96821590335364\n",
      "loss: 97.96303051029403\n",
      "loss: 97.958337924541\n",
      "loss: 97.95350097574443\n",
      "loss: 97.94864884056332\n",
      "loss: 97.94370637646203\n",
      "loss: 97.93866805119684\n",
      "loss: 97.93266834883663\n",
      "loss: 97.92462374636008\n",
      "loss: 97.91826840780847\n",
      "loss: 97.91143552438642\n",
      "loss: 97.903507076187\n",
      "loss: 97.89545508537121\n",
      "loss: 97.88743282968693\n",
      "loss: 97.87917174035991\n",
      "test loss: 89.76447851271318\n",
      "STEP:  94\n",
      "loss: 97.87073684474065\n",
      "loss: 97.8620731742114\n",
      "loss: 97.85328170918996\n",
      "loss: 97.8442905281628\n",
      "loss: 97.83521714608516\n",
      "loss: 97.82596627551943\n",
      "loss: 97.81667813210488\n",
      "loss: 97.80723423131657\n",
      "loss: 97.79779425863664\n",
      "loss: 97.78822352616773\n",
      "loss: 97.77869343562979\n",
      "loss: 97.76906027344533\n",
      "loss: 97.75949518057692\n",
      "loss: 97.74985167045205\n",
      "loss: 97.74029286699886\n",
      "loss: 97.7306749816122\n",
      "loss: 97.72115233697767\n",
      "loss: 97.71158723699996\n",
      "loss: 97.70212632459847\n",
      "loss: 97.69263880882612\n",
      "test loss: 90.06236596409165\n",
      "STEP:  95\n",
      "loss: 97.68326353984124\n",
      "loss: 97.67387692962012\n",
      "loss: 97.6646097256757\n",
      "loss: 97.65534566131473\n",
      "loss: 97.6462066442391\n",
      "loss: 97.63708399105249\n",
      "loss: 97.62809061810759\n",
      "loss: 97.61912603729004\n",
      "loss: 97.61030527077322\n",
      "loss: 97.60153043780899\n",
      "loss: 97.59287184785242\n",
      "loss: 97.58425317484068\n",
      "loss: 97.57576186816806\n",
      "loss: 97.56732642557249\n",
      "loss: 97.5590108201952\n",
      "loss: 97.55074794172482\n",
      "loss: 97.54260912277753\n",
      "loss: 97.53453217138464\n",
      "loss: 97.52657442113733\n",
      "loss: 97.51867849396872\n",
      "test loss: 90.20615680199839\n",
      "STEP:  96\n",
      "loss: 97.51090033063777\n",
      "loss: 97.50318335362236\n",
      "loss: 97.49557618102142\n",
      "loss: 97.48801239516793\n",
      "loss: 97.48054098346675\n",
      "loss: 97.47299395443476\n",
      "loss: 97.46552564704729\n",
      "loss: 97.45238664070288\n",
      "loss: 97.44557420803979\n",
      "loss: 97.43849200014382\n",
      "loss: 97.431443583012\n",
      "loss: 97.42446740560972\n",
      "loss: 97.41770525144135\n",
      "loss: 97.41111882796048\n",
      "loss: 97.40470918387521\n",
      "loss: 97.39841210219785\n",
      "loss: 97.39221266607166\n",
      "loss: 97.38607722501985\n",
      "loss: 97.38002028456337\n",
      "loss: 97.37401689198481\n",
      "test loss: 90.21143227395127\n",
      "STEP:  97\n",
      "loss: 97.36809731328239\n",
      "loss: 97.36223809799353\n",
      "loss: 97.35646601092334\n",
      "loss: 97.35075832398249\n",
      "loss: 97.34513985168702\n",
      "loss: 97.33958752673222\n",
      "loss: 97.33412470224768\n",
      "loss: 97.32872787540198\n",
      "loss: 97.32341864998124\n",
      "loss: 97.31817281897669\n",
      "loss: 97.31300829498882\n",
      "loss: 97.30789818087327\n",
      "loss: 97.30278425830645\n",
      "loss: 97.29774568868386\n",
      "loss: 97.29287636633475\n",
      "loss: 97.287996870692\n",
      "loss: 97.283161966398\n",
      "loss: 97.27840980462118\n",
      "loss: 97.27364961672438\n",
      "loss: 97.26896064020738\n",
      "test loss: 90.21135641341588\n",
      "STEP:  98\n",
      "loss: 97.2641921080585\n",
      "loss: 97.25968090910706\n",
      "loss: 97.25456796097146\n",
      "loss: 97.25042508132653\n",
      "loss: 97.24620365679527\n",
      "loss: 97.24174301057926\n",
      "loss: 97.23407594412762\n",
      "loss: 97.22888708248695\n",
      "loss: 97.22451322202267\n",
      "loss: 97.22056610667805\n",
      "loss: 97.21661431249056\n",
      "loss: 97.2126931379648\n",
      "loss: 97.20883617189925\n",
      "loss: 97.20504003813517\n",
      "loss: 97.20126488663946\n",
      "loss: 97.197490321626\n",
      "loss: 97.19363646847289\n",
      "loss: 97.18971611835134\n",
      "loss: 97.18577355094557\n",
      "loss: 97.1817977748371\n",
      "test loss: 90.17999049372713\n",
      "STEP:  99\n",
      "loss: 97.1777645990646\n",
      "loss: 97.17367611644399\n",
      "loss: 97.16956929550159\n",
      "loss: 97.16543815343049\n",
      "loss: 97.16130310566263\n",
      "loss: 97.15715201639802\n",
      "loss: 97.15299278336865\n",
      "loss: 97.14882019123095\n",
      "loss: 97.14465387964333\n",
      "loss: 97.14048435371824\n",
      "loss: 97.13632888200821\n",
      "loss: 97.13217849809273\n",
      "loss: 97.12804954529581\n",
      "loss: 97.12393319574602\n",
      "loss: 97.11984356011695\n",
      "loss: 97.11577160037464\n",
      "loss: 97.11172990831868\n",
      "loss: 97.10770901862792\n",
      "loss: 97.10372045555314\n",
      "loss: 97.09975441437554\n",
      "test loss: 90.15240107341974\n"
     ]
    }
   ],
   "source": [
    " # set random seed to 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# load data and make training set\n",
    "train_data = np.asarray(X)\n",
    "val_data = np.asarray(test)\n",
    "input = torch.from_numpy(train_data[:, :-1])\n",
    "target = torch.from_numpy(train_data[:, 1:])\n",
    "test_input = torch.from_numpy(val_data[:, :-1])\n",
    "test_target = torch.from_numpy(val_data[:, 1:])\n",
    "\n",
    "# build the model\n",
    "seq = Sequence()\n",
    "seq.double()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# use LBFGS as optimizer\n",
    "optimizer = optim.LBFGS(seq.parameters(), lr=0.01)\n",
    "\n",
    "#begin to train\n",
    "for i in range(100):\n",
    "    print('STEP: ', i)\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = seq(input)\n",
    "        loss = criterion(out, target)\n",
    "        print('loss:', loss.item())\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optimizer.step(closure)\n",
    "    # begin to predict\n",
    "    with torch.no_grad():\n",
    "        future = 1\n",
    "        pred = seq(test_input, future=future)\n",
    "        loss = criterion(pred[:, :-future], test_target)\n",
    "        print('test loss:', loss.item())\n",
    "        y = pred.detach().numpy()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "https://github.com/pytorch/examples/blob/master/time_sequence_prediction/train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
